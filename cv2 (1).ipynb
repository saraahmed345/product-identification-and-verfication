{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-24T20:39:03.185057Z",
     "iopub.status.busy": "2023-12-24T20:39:03.184645Z",
     "iopub.status.idle": "2023-12-24T20:39:37.920890Z",
     "shell.execute_reply": "2023-12-24T20:39:37.918867Z",
     "shell.execute_reply.started": "2023-12-24T20:39:03.185022Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Dec 23 21:38:29 2023\n",
    "\n",
    "@author: DELL\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import keras.layers\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import layers, metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "ROOT = r\"C:\\Users\\DELL\\Downloads\\Data\\Product Recoginition\"\n",
    "Validation_Data = r\"C:\\Users\\DELL\\Downloads\\Data\\Product Recoginition\\Validation Data\"\n",
    "Training_Data = r\"C:\\Users\\DELL\\Downloads\\Data\\Product Recoginition\\Training Data\"\n",
    "\n",
    "def is_image_readable(image_path):\n",
    "    try:\n",
    "        # Attempt to read the image\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        if img is None:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading image: {image_path}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def getFiles(path=\"\"):\n",
    "    imlist = {}\n",
    "    count = 0\n",
    "   \n",
    "    for each in os.listdir(path):\n",
    "        imlist[each] = []\n",
    "        for imagefile in os.listdir(path + '/' + each):\n",
    "            image_path = path + '/' + each + '/' + imagefile\n",
    "            if is_image_readable(image_path):\n",
    "                # Read the image using OpenCV\n",
    "                im = cv2.imread(image_path)\n",
    "\n",
    "                # Convert BGR to RGB\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                im = cv2.resize(im, (128, 128))\n",
    "\n",
    "                # Resize the image\n",
    "\n",
    "                # Apply data augmentation\n",
    "               \n",
    "                imlist[each].append(im)\n",
    "                count += 1\n",
    "\n",
    "               \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return [imlist, count]\n",
    "\n",
    "   \n",
    "\n",
    "def look(directory):\n",
    "    folders = os.listdir(directory)\n",
    "\n",
    "    train_list = {}\n",
    "    for folder in folders:\n",
    "        num_files = len(os.listdir(os.path.join(directory, folder)))\n",
    "        train_list[folder] = num_files\n",
    "\n",
    "    return train_list\n",
    "\n",
    "#train_list = look(Training_Data)\n",
    "train_list, _ = getFiles(Training_Data)\n",
    "val_list, _=getFiles(Validation_Data)\n",
    "print(\"Length of training list:\", len(train_list))\n",
    "print(len(train_list.items()))\n",
    "print(\"\\ntraing List:\", train_list)\n",
    "#val_list = look(Validation_Data)\n",
    "print(\"Length of training list:\", len(val_list))\n",
    "print(\"\\ntraing List:\", val_list)\n",
    "def create_triplets(directory, folder_list, max_files=14):\n",
    "    triplets = []\n",
    "    folders = list(folder_list.keys())\n",
    "\n",
    "    for folder in folders:\n",
    "        path = os.path.join(directory, folder)\n",
    "        files = list(os.listdir(path))[:max_files]\n",
    "        num_files = len(files)\n",
    "\n",
    "        for i in range(num_files - 1):\n",
    "            for j in range(i + 1, num_files):\n",
    "                anchor_filename = f\"web{i+1}.png\"\n",
    "                positive_filename = f\"web{j}.png\"\n",
    "\n",
    "                anchor_path = os.path.join(path, anchor_filename)\n",
    "                positive_path = os.path.join(path, positive_filename)\n",
    "\n",
    "                if is_image_readable(anchor_path) and is_image_readable(positive_path):\n",
    "                    anchor_image = cv2.imread(anchor_path)\n",
    "                    positive_image = cv2.imread(positive_path)\n",
    "\n",
    "                    anchor_image = cv2.cvtColor(anchor_image, cv2.COLOR_BGR2RGB)\n",
    "                    positive_image = cv2.cvtColor(positive_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    anchor_image = cv2.resize(anchor_image, (128, 128))\n",
    "                    positive_image = cv2.resize(positive_image, (128, 128))\n",
    "\n",
    "                    anchor = (folder, anchor_image)\n",
    "                    positive = (folder, positive_image)\n",
    "\n",
    "                    # Find a negative image\n",
    "                    neg_folder = folder\n",
    "                    while neg_folder == folder:\n",
    "                        neg_folder = random.choice(folders)\n",
    "                    neg_file = random.randint(0, len(folder_list[neg_folder]) - 1)\n",
    "                    neg_filename = f\"web{neg_file + 1}.png\"  # Adding 1 to avoid a 0 filename\n",
    "                    neg_path = os.path.join(directory, neg_folder, neg_filename)\n",
    "\n",
    "                    if is_image_readable(neg_path):\n",
    "                        neg_image = cv2.imread(neg_path)\n",
    "                        neg_image = cv2.cvtColor(neg_image, cv2.COLOR_BGR2RGB)\n",
    "                        neg_image = cv2.resize(neg_image, (128, 128))\n",
    "                        negative = (neg_folder, neg_image)\n",
    "\n",
    "                        triplets.append((anchor, positive, negative))\n",
    "                    else:\n",
    "                        print(f\"Error reading negative image: {neg_path}\")\n",
    "                else:\n",
    "                    print(f\"Error reading anchor or positive image: {anchor_path}, {positive_path}\")\n",
    "\n",
    "    random.shuffle(triplets)\n",
    "    return triplets\n",
    "\n",
    "\n",
    "train_triplet = create_triplets(Training_Data, train_list)\n",
    "test_triplet  = create_triplets(Validation_Data, val_list)\n",
    "\n",
    "print(\"Number of training triplets:\", len(train_triplet))\n",
    "print(\"Number of testing triplets :\", len(test_triplet))\n",
    "\n",
    "\n",
    "print(\"\\nExamples of triplets:\")\n",
    "for i in range(5):\n",
    "    print(train_triplet[i])\n",
    "def get_batch(triplet_list, batch_size=256, preprocess=True):\n",
    "    batch_steps = len(triplet_list) // batch_size\n",
    "\n",
    "    for i in range(batch_steps + 1):\n",
    "        anchor = []\n",
    "        positive = []\n",
    "        negative = []\n",
    "\n",
    "        j = i * batch_size\n",
    "        while j < (i + 1) * batch_size and j < len(triplet_list):\n",
    "            anchor_triplet, positive_triplet, negative_triplet = triplet_list[j]\n",
    "\n",
    "            # Extracting paths\n",
    "            a_folder, a_img = anchor_triplet\n",
    "            p_folder, p_img = positive_triplet\n",
    "            n_folder, n_img = negative_triplet\n",
    "\n",
    "            # Reading and processing images\n",
    "            anchor_image = cv2.cvtColor(a_img, cv2.COLOR_BGR2RGB)\n",
    "            positive_image = cv2.cvtColor(p_img, cv2.COLOR_BGR2RGB)\n",
    "            negative_image = cv2.cvtColor(n_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            anchor_image = cv2.resize(anchor_image, (128, 128))\n",
    "            positive_image = cv2.resize(positive_image, (128, 128))\n",
    "            negative_image = cv2.resize(negative_image, (128, 128))\n",
    "\n",
    "            anchor.append(anchor_image)\n",
    "            positive.append(positive_image)\n",
    "            negative.append(negative_image)\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        # Check if any anchor, positive, or negative image is empty, skip iteration if so\n",
    "        if not anchor or not positive or not negative:\n",
    "            continue\n",
    "\n",
    "        # Convert anchor, positive, and negative lists to arrays\n",
    "        anchor = np.array(anchor)\n",
    "        positive = np.array(positive)\n",
    "        negative = np.array(negative)\n",
    "\n",
    "        if preprocess:\n",
    "            anchor = preprocess_input(anchor)\n",
    "            positive = preprocess_input(positive)\n",
    "            negative = preprocess_input(negative)\n",
    "\n",
    "        yield ([anchor, positive, negative])\n",
    "        \n",
    "num_plots=6\n",
    "f, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n",
    "\n",
    "for i, (a, p, n) in enumerate(get_batch(train_triplet, batch_size=num_plots, preprocess=False)):\n",
    "    axes[i, 0].imshow(a[0])  \n",
    "    axes[i, 1].imshow(p[0])\n",
    "    axes[i, 2].imshow(n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-24T20:39:37.922153Z",
     "iopub.status.idle": "2023-12-24T20:39:37.922526Z",
     "shell.execute_reply": "2023-12-24T20:39:37.922384Z",
     "shell.execute_reply.started": "2023-12-24T20:39:37.922368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"Siamese_Network\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Anchor_Input (InputLayer)   [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Positive_Input (InputLayer  [(None, 128, 128, 3)]        0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Negative_Input (InputLayer  [(None, 128, 128, 3)]        0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mobilenetv2_1.00_128 (Func  (None, 1280)                 2257984   ['Anchor_Input[0][0]',        \n",
      " tional)                                                             'Positive_Input[0][0]',      \n",
      "                                                                     'Negative_Input[0][0]']      \n",
      "                                                                                                  \n",
      " distance_layer (DistanceLa  ((None,),                    0         ['mobilenetv2_1.00_128[3][0]',\n",
      " yer)                         (None,))                               'mobilenetv2_1.00_128[4][0]',\n",
      "                                                                     'mobilenetv2_1.00_128[5][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2257984 (8.61 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "def get_encoder(input_shape):\n",
    "    pretrained_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "    )\n",
    "\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return pretrained_model\n",
    "class DistanceLayer(layers.Layer):\n",
    "    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "    \n",
    "\n",
    "def get_siamese_network(input_shape = (128, 128, 3)):\n",
    "    encoder = get_encoder(input_shape)\n",
    "    \n",
    "    # Input Layers for the images\n",
    "    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n",
    "    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n",
    "    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n",
    "    \n",
    "    ## Generate the encodings (feature vectors) for the images\n",
    "    encoded_a = encoder(anchor_input)\n",
    "    encoded_p = encoder(positive_input)\n",
    "    encoded_n = encoder(negative_input)\n",
    "    \n",
    "    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n",
    "    distances = DistanceLayer()(\n",
    "        encoder(anchor_input),\n",
    "        encoder(positive_input),\n",
    "        encoder(negative_input)\n",
    "    )\n",
    "    \n",
    "    # Creating the Model\n",
    "    siamese_network = Model(\n",
    "        inputs  = [anchor_input, positive_input, negative_input],\n",
    "        outputs = distances,\n",
    "        name = \"Siamese_Network\"\n",
    "    )\n",
    "    return siamese_network\n",
    "\n",
    "siamese_network = get_siamese_network()\n",
    "siamese_network.summary()\n",
    "class SiameseModel(Model):\n",
    "    # Builds a Siamese model based on a base-model\n",
    "    def __init__(self, siamese_network, margin=1.0):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        \n",
    "        self.margin = margin\n",
    "        self.siamese_network = siamese_network\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # Get the two distances from the network, then compute the triplet loss\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics so the reset_states() can be called automatically.\n",
    "        return [self.loss_tracker]\n",
    "siamese_model = SiameseModel(siamese_network)\n",
    "optimizer = Adam(learning_rate=1e-3, epsilon=1e-01)\n",
    "siamese_model.compile(optimizer=optimizer,run_eagerly=True)\n",
    "def test_on_triplets(batch_size = 16):\n",
    "    pos_scores, neg_scores = [], []\n",
    "\n",
    "    for data in get_batch(test_triplet, batch_size=batch_size):\n",
    "        prediction = siamese_model.predict(data)\n",
    "        pos_scores += list(prediction[0])\n",
    "        neg_scores += list(prediction[1])\n",
    "    \n",
    "    accuracy = np.sum(np.array(pos_scores) < np.array(neg_scores)) / len(pos_scores)\n",
    "    ap_mean = np.mean(pos_scores)\n",
    "    an_mean = np.mean(neg_scores)\n",
    "    ap_stds = np.std(pos_scores)\n",
    "    an_stds = np.std(neg_scores)\n",
    "    \n",
    "    print(f\"Accuracy on test = {accuracy:.5f}\")\n",
    "    return (accuracy, ap_mean, an_mean, ap_stds, an_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-24T20:39:37.923800Z",
     "iopub.status.idle": "2023-12-24T20:39:37.924241Z",
     "shell.execute_reply": "2023-12-24T20:39:37.924096Z",
     "shell.execute_reply.started": "2023-12-24T20:39:37.924076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 1 \t (Epoch done in 121 sec)\n",
      "Loss on train    = 9.27249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 845ms/step\n",
      "1/1 [==============================] - 1s 810ms/step\n",
      "1/1 [==============================] - 1s 780ms/step\n",
      "1/1 [==============================] - 1s 787ms/step\n",
      "1/1 [==============================] - 1s 768ms/step\n",
      "1/1 [==============================] - 1s 756ms/step\n",
      "1/1 [==============================] - 1s 764ms/step\n",
      "1/1 [==============================] - 1s 765ms/step\n",
      "1/1 [==============================] - 1s 885ms/step\n",
      "1/1 [==============================] - 1s 844ms/step\n",
      "1/1 [==============================] - 1s 910ms/step\n",
      "1/1 [==============================] - 1s 787ms/step\n",
      "1/1 [==============================] - 1s 847ms/step\n",
      "1/1 [==============================] - 1s 808ms/step\n",
      "1/1 [==============================] - 1s 788ms/step\n",
      "1/1 [==============================] - 1s 786ms/step\n",
      "1/1 [==============================] - 1s 795ms/step\n",
      "1/1 [==============================] - 1s 784ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 2 \t (Epoch done in 115 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 744ms/step\n",
      "1/1 [==============================] - 1s 714ms/step\n",
      "1/1 [==============================] - 1s 704ms/step\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "1/1 [==============================] - 1s 814ms/step\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "1/1 [==============================] - 1s 829ms/step\n",
      "1/1 [==============================] - 1s 724ms/step\n",
      "1/1 [==============================] - 1s 765ms/step\n",
      "1/1 [==============================] - 1s 718ms/step\n",
      "1/1 [==============================] - 1s 698ms/step\n",
      "1/1 [==============================] - 1s 708ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1/1 [==============================] - 1s 717ms/step\n",
      "1/1 [==============================] - 1s 707ms/step\n",
      "1/1 [==============================] - 1s 706ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1/1 [==============================] - 1s 702ms/step\n",
      "1/1 [==============================] - 1s 587ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 3 \t (Epoch done in 110 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 728ms/step\n",
      "1/1 [==============================] - 1s 704ms/step\n",
      "1/1 [==============================] - 1s 704ms/step\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "1/1 [==============================] - 1s 715ms/step\n",
      "1/1 [==============================] - 1s 705ms/step\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "1/1 [==============================] - 1s 788ms/step\n",
      "1/1 [==============================] - 1s 868ms/step\n",
      "1/1 [==============================] - 1s 797ms/step\n",
      "1/1 [==============================] - 1s 837ms/step\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "1/1 [==============================] - 1s 804ms/step\n",
      "1/1 [==============================] - 1s 760ms/step\n",
      "1/1 [==============================] - 1s 764ms/step\n",
      "1/1 [==============================] - 1s 755ms/step\n",
      "1/1 [==============================] - 1s 712ms/step\n",
      "1/1 [==============================] - 1s 588ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 4 \t (Epoch done in 116 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 772ms/step\n",
      "1/1 [==============================] - 1s 758ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 863ms/step\n",
      "1/1 [==============================] - 1s 873ms/step\n",
      "1/1 [==============================] - 1s 920ms/step\n",
      "1/1 [==============================] - 1s 883ms/step\n",
      "1/1 [==============================] - 1s 809ms/step\n",
      "1/1 [==============================] - 1s 799ms/step\n",
      "1/1 [==============================] - 1s 811ms/step\n",
      "1/1 [==============================] - 1s 814ms/step\n",
      "1/1 [==============================] - 1s 810ms/step\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 1s 803ms/step\n",
      "1/1 [==============================] - 1s 809ms/step\n",
      "1/1 [==============================] - 1s 734ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 5 \t (Epoch done in 138 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 903ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 1s 833ms/step\n",
      "1/1 [==============================] - 1s 896ms/step\n",
      "1/1 [==============================] - 1s 972ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 949ms/step\n",
      "1/1 [==============================] - 1s 864ms/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 790ms/step\n",
      "1/1 [==============================] - 1s 781ms/step\n",
      "1/1 [==============================] - 1s 775ms/step\n",
      "1/1 [==============================] - 1s 760ms/step\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "1/1 [==============================] - 1s 740ms/step\n",
      "1/1 [==============================] - 1s 744ms/step\n",
      "1/1 [==============================] - 1s 622ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 6 \t (Epoch done in 124 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 795ms/step\n",
      "1/1 [==============================] - 1s 775ms/step\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "1/1 [==============================] - 1s 747ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "1/1 [==============================] - 1s 734ms/step\n",
      "1/1 [==============================] - 1s 740ms/step\n",
      "1/1 [==============================] - 1s 853ms/step\n",
      "1/1 [==============================] - 1s 823ms/step\n",
      "1/1 [==============================] - 1s 879ms/step\n",
      "1/1 [==============================] - 1s 796ms/step\n",
      "1/1 [==============================] - 1s 797ms/step\n",
      "1/1 [==============================] - 1s 752ms/step\n",
      "1/1 [==============================] - 1s 756ms/step\n",
      "1/1 [==============================] - 1s 738ms/step\n",
      "1/1 [==============================] - 1s 738ms/step\n",
      "1/1 [==============================] - 1s 754ms/step\n",
      "1/1 [==============================] - 1s 736ms/step\n",
      "1/1 [==============================] - 1s 610ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 7 \t (Epoch done in 121 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 780ms/step\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "1/1 [==============================] - 1s 757ms/step\n",
      "1/1 [==============================] - 1s 731ms/step\n",
      "1/1 [==============================] - 1s 727ms/step\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "1/1 [==============================] - 1s 793ms/step\n",
      "1/1 [==============================] - 1s 795ms/step\n",
      "1/1 [==============================] - 1s 910ms/step\n",
      "1/1 [==============================] - 1s 724ms/step\n",
      "1/1 [==============================] - 1s 720ms/step\n",
      "1/1 [==============================] - 1s 840ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 873ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 873ms/step\n",
      "1/1 [==============================] - 1s 971ms/step\n",
      "1/1 [==============================] - 1s 847ms/step\n",
      "1/1 [==============================] - 1s 776ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 8 \t (Epoch done in 115 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 769ms/step\n",
      "1/1 [==============================] - 1s 747ms/step\n",
      "1/1 [==============================] - 1s 717ms/step\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "1/1 [==============================] - 1s 727ms/step\n",
      "1/1 [==============================] - 1s 726ms/step\n",
      "1/1 [==============================] - 1s 724ms/step\n",
      "1/1 [==============================] - 1s 720ms/step\n",
      "1/1 [==============================] - 1s 727ms/step\n",
      "1/1 [==============================] - 1s 843ms/step\n",
      "1/1 [==============================] - 1s 868ms/step\n",
      "1/1 [==============================] - 1s 932ms/step\n",
      "1/1 [==============================] - 1s 852ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 922ms/step\n",
      "1/1 [==============================] - 1s 958ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 9 \t (Epoch done in 137 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 760ms/step\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "1/1 [==============================] - 1s 757ms/step\n",
      "1/1 [==============================] - 1s 735ms/step\n",
      "1/1 [==============================] - 1s 755ms/step\n",
      "1/1 [==============================] - 1s 761ms/step\n",
      "1/1 [==============================] - 1s 725ms/step\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "1/1 [==============================] - 1s 756ms/step\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "1/1 [==============================] - 1s 745ms/step\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "1/1 [==============================] - 1s 735ms/step\n",
      "1/1 [==============================] - 1s 725ms/step\n",
      "1/1 [==============================] - 1s 728ms/step\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "1/1 [==============================] - 1s 788ms/step\n",
      "1/1 [==============================] - 1s 821ms/step\n",
      "1/1 [==============================] - 1s 702ms/step\n",
      "Accuracy on test = 0.95000\n",
      "\n",
      "EPOCH: 10 \t (Epoch done in 116 sec)\n",
      "Loss on train    = 9.27249\n",
      "1/1 [==============================] - 1s 759ms/step\n",
      "1/1 [==============================] - 1s 762ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "1/1 [==============================] - 1s 727ms/step\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "1/1 [==============================] - 1s 728ms/step\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "1/1 [==============================] - 1s 740ms/step\n",
      "1/1 [==============================] - 1s 729ms/step\n",
      "1/1 [==============================] - 1s 735ms/step\n",
      "1/1 [==============================] - 1s 820ms/step\n",
      "1/1 [==============================] - 1s 802ms/step\n",
      "1/1 [==============================] - 1s 848ms/step\n",
      "1/1 [==============================] - 1s 832ms/step\n",
      "1/1 [==============================] - 1s 775ms/step\n",
      "1/1 [==============================] - 1s 747ms/step\n",
      "1/1 [==============================] - 1s 742ms/step\n",
      "1/1 [==============================] - 1s 602ms/step\n",
      "Accuracy on test = 0.95000\n",
      "Model: \"mobilenetv2_1.00_128\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 64, 64, 32)           864       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 64, 64, 32)           128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 64, 64, 32)           0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 64, 64, 32)           288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 64, 64, 32)           128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 64, 64, 32)           0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 64, 64, 16)           512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 64, 64, 16)           64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 64, 64, 96)           1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 64, 64, 96)           384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 64, 64, 96)           0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 65, 65, 96)           0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 32, 32, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 32, 32, 24)           96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 32, 32, 144)          3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 32, 32, 144)          576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 32, 32, 144)          0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 32, 32, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 32, 32, 144)          576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 32, 32, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 32, 32, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 32, 32, 24)           96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 32, 32, 24)           0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 32, 32, 144)          3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 32, 32, 144)          576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 32, 32, 144)          0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 33, 33, 144)          0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 16, 16, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 16, 16, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 16, 16, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 16, 16, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 16, 16, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 16, 16, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 16, 16, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 16, 16, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 16, 16, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 16, 16, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 16, 16, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 16, 16, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 16, 16, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 16, 16, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 16, 16, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 16, 16, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 16, 16, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 16, 16, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 16, 16, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 16, 16, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 16, 16, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 16, 16, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 16, 16, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 16, 16, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 16, 16, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 16, 16, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 17, 17, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 8, 8, 192)            1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 8, 8, 192)            768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 8, 8, 192)            0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 8, 8, 64)             12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 8, 8, 384)            24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 8, 8, 384)            1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 8, 8, 384)            0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 8, 8, 384)            3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 8, 8, 384)            1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 8, 8, 384)            0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 8, 8, 64)             24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 8, 8, 64)             0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 8, 8, 384)            24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 8, 8, 384)            1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 8, 8, 384)            0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 8, 8, 384)            3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 8, 8, 384)            1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 8, 8, 384)            0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 8, 8, 64)             24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 8, 8, 64)             0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 8, 8, 384)            24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 8, 8, 384)            1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 8, 8, 384)            0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 8, 8, 384)            3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 8, 8, 384)            1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 8, 8, 384)            0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 8, 8, 64)             24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 8, 8, 64)             0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 8, 8, 384)            24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 8, 8, 384)            1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 8, 8, 384)            0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 8, 8, 384)            3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 8, 8, 384)            1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 8, 8, 384)            0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 8, 8, 96)             36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 8, 8, 96)             384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 8, 8, 576)            55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 8, 8, 576)            2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 8, 8, 576)            0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 8, 8, 576)            5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 8, 8, 576)            2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 8, 8, 576)            0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 8, 8, 96)             55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 8, 8, 96)             384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 8, 8, 96)             0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 8, 8, 576)            55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 8, 8, 576)            2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 8, 8, 576)            0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 8, 8, 576)            5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 8, 8, 576)            2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 8, 8, 576)            0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 8, 8, 96)             55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 8, 8, 96)             384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 8, 8, 96)             0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 8, 8, 576)            55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 8, 8, 576)            2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 8, 8, 576)            0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 9, 9, 576)            0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 4, 4, 576)            5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 4, 4, 576)            2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 4, 4, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 4, 4, 160)            92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 4, 4, 160)            640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 4, 4, 960)            153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 4, 4, 960)            3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 4, 4, 960)            0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 4, 4, 960)            8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 4, 4, 960)            3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 4, 4, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 4, 4, 160)            153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 4, 4, 160)            640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 4, 4, 160)            0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 4, 4, 960)            153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 4, 4, 960)            3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 4, 4, 960)            0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 4, 4, 960)            8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 4, 4, 960)            3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 4, 4, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 4, 4, 160)            153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 4, 4, 160)            640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 4, 4, 160)            0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 4, 4, 960)            153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 4, 4, 960)            3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 4, 4, 960)            0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 4, 4, 960)            8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 4, 4, 960)            3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 4, 4, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 4, 4, 320)            307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 4, 4, 320)            1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 4, 4, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 4, 4, 1280)           5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 4, 4, 1280)           0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 1280)                 0         ['out_relu[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2257984 (8.61 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "save_all = False\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "max_acc = 0\n",
    "train_loss = []\n",
    "test_metrics = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    t = time.time()\n",
    "    \n",
    "    # Training the model on train data\n",
    "    epoch_loss = []\n",
    "    for data in get_batch(train_triplet, batch_size=batch_size):\n",
    "        loss = siamese_model.train_on_batch(data)\n",
    "        epoch_loss.append(loss)\n",
    "    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n",
    "    print(f\"Loss on train    = {epoch_loss:.5f}\")\n",
    "    \n",
    "    # Testing the model on test data\n",
    "    metric = test_on_triplets(batch_size=batch_size)\n",
    "    test_metrics.append(metric)\n",
    "    accuracy = metric[0]\n",
    "    \n",
    "    # Saving the model weights\n",
    "    if save_all or accuracy>=max_acc:\n",
    "        siamese_model.save_weights(\"siamese_model\")\n",
    "        max_acc = accuracy\n",
    "\n",
    "# Saving the model after all epochs run\n",
    "siamese_model.save_weights(\"siamese_model-final\")\n",
    "def extract_encoder(model):\n",
    "    encoder = get_encoder((128, 128, 3))\n",
    "    i=0\n",
    "    for e_layer in model.layers[0].layers[3].layers:\n",
    "        layer_weight = e_layer.get_weights()\n",
    "        encoder.layers[i].set_weights(layer_weight)\n",
    "        i+=1\n",
    "    return encoder\n",
    "\n",
    "encoder = extract_encoder(siamese_model)\n",
    "encoder.save_weights(\"encoder\")\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-24T20:39:37.925182Z",
     "iopub.status.idle": "2023-12-24T20:39:37.925515Z",
     "shell.execute_reply": "2023-12-24T20:39:37.925381Z",
     "shell.execute_reply.started": "2023-12-24T20:39:37.925366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "\n",
      "Accuracy of model: 0.625\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify_images(face_list1, face_list2, threshold=1.3):\n",
    "    # Getting the encodings for the passed faces\n",
    "    tensor1 = encoder.predict(face_list1)\n",
    "    tensor2 = encoder.predict(face_list2)\n",
    "    \n",
    "    distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n",
    "    prediction = np.where(distance<=threshold, 0, 1)\n",
    "    return prediction\n",
    "def ModelMetrics(pos_list, neg_list):\n",
    "    true = np.array([0]*len(pos_list)+[1]*len(neg_list))\n",
    "    pred = np.append(pos_list, neg_list)\n",
    "    \n",
    "    # Compute and print the accuracy\n",
    "    print(f\"\\nAccuracy of model: {accuracy_score(true, pred)}\\n\")\n",
    "    \n",
    "    # Compute and plot the Confusion matrix\n",
    "    cf_matrix = confusion_matrix(true, pred)\n",
    "\n",
    "    categories  = ['Similar','Different']\n",
    "    names = ['True Similar','False Similar', 'False Different','True Different']\n",
    "    percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(names, percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
    "                xticklabels = categories, yticklabels = categories)\n",
    "\n",
    "    plt.xlabel(\"Predicted\", fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.ylabel(\"Actual\"   , fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n",
    "\n",
    "\n",
    "pos_list = np.array([])\n",
    "neg_list = np.array([])\n",
    "\n",
    "for data in get_batch(test_triplet, batch_size=16):\n",
    "    a, p, n = data\n",
    "    pos_list = np.append(pos_list, classify_images(a, p))\n",
    "    neg_list = np.append(neg_list, classify_images(a, n))\n",
    "    break\n",
    "\n",
    "ModelMetrics(pos_list, neg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4213862,
     "sourceId": 7269254,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
